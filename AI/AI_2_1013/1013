### y = ax

선형회귀 :  큰수의 법칙으로 데이터를 모아모아 a라는 ‘경향’을 분석하는 과정.

(이 기울기인 a를 Parameter 라고 함)

→ ML 란 이 파라미터를 모으는 역할

### 정규방정식을 이용한 선형대수적 풀이

선형회귀 모델을 구현할 때, 범주형 변수는 잘 안쓰고 연속형 변수를 쓴다. → Why?

![image.png](attachment:0922ec25-7705-451a-92c1-080311df4a54:image.png)

mean(평균), std(표준편차) 란…

- **`categorical_cols` (범주형 변수)**
    - `df.select_dtypes(include=['category'])`: `df`에서 데이터 타입이 'category'인 열들만 선택합니다. (예: cut, color, clarity)
    - `.columns`: 선택된 열들의 이름을 가져옵니다.
    - `.tolist()`: 열 이름들을 파이썬 리스트 형태로 변환하여 `categorical_cols` 변수에 저장합니다.
- **`continuous_cols` (연속형 변수)**
    - `df.select_dtypes(include=['number'])`: `df`에서 데이터 타입이 숫자형('number')인 열들만 선택합니다. (예: carat, depth, table, price, x, y, z)
    - 위와 마찬가지로 열 이름들을 리스트로 변환하여 `continuous_cols` 변수에 저장합니다.

결론적으로, 이 코드는 **데이터를 처음 받았을 때 데이터의 구조와 특성을 파악(EDA, 탐색적 데이터 분석)하는 가장 기본적인 단계**를 보여줍니다.

연속형 변수(`continuous_cols`)들을 표준화(Standardization)하는 과정

```python

# 1. 연속형 변수 선택 및 NumPy 배열 변환
# 연속된 변수들만 뽑아서 저장
X_raw = df[continuous_cols].values

# 2. 평균 및 표준편차 계산
# 해당 변수들의 평균을 구한다
mu = X_raw.mean(axis=0)     # axis : 어떤 행렬로 평균 구할건지

# 3. 표준편차가 0일 경우 처리 (안정성 확보)
# 해당 변수들의 표준편차를 구한다
std = X_raw.std(axis=0)

# 표준편차가 0이 될 경우 바꿔준다.
# 1. 1로 바꾸거나
std = np.where(std == 0, 1.0, std)
# 2. 아주 작은 값으로 바꾸거나
epsilon = 1e-8
std = np.where(std == 0, epsilon, std)

# 4. 표준화(Standardization) 수행
# 표준화된 x 값들을 구한다
X_norm = (X_raw - mu) / std
print(X_norm)
```

결론적으로, 이 코드는 연속형 데이터의 스케일을 통일하여 머신러닝 모델이 더 잘 학습할 수 있도록 **데이터를 표준화하는 전처리 과정**을 수행

### 경사하강법

U자 선그래프에서 경사를 줄이며 theta를 찾는 법

---

# AI 강의

## **데이터**

ML은 규칙을 **직접 코딩하지 않고**, 데이터에서 규칙을 학습

- **Feature (피처, 특성)**
    
    : 모델이 예측에 사용하는 입력정보 및 예측, 판단의 근거
    
- **Label ( 라벨, 목표값 )**
    
    : 모델이 예측하려는 정답 및 학습의 목표값
    

## 단일 피쳐 기반 학습

- **1D(1차원) 피쳐 기반 학습**
    
    : Feature가 하나일때, 머신러닝이 학습하는 가장 단순한 형태
    
    ![image.png](attachment:bb4fa6d9-4cb5-4b77-9c98-ae919100d0b6:image.png)
    
    ![image.png](attachment:1c8926c8-ff91-4985-aa85-ad1385c29581:image.png)
    
- **학습 (Learning)**
    
    “입력(Feature) → 출력(Label) 의 관계를 찾는 과정”
    
    : 평균 관계를 하나의 함수로 표현함 ( but, 관계를 표현할 수 있는 함수는 무수히 많음 )
    
    → 주어진 데이터와 성능척도를 바탕으로 가설공간 F의 후보들 중 최적의 모델을 선택하는 과정
    
- **가설 공간 (Hypothesis Space)**
    
     : 관계를 표현할 수 있는 모든 후보 함수들의 모음
    
     : 피쳐 공간과 라벨 공간 위에서 정의된 함수들의 집합 F
    
- **모델**
    
    : 가설 공간 F 에 속한 특정 함수 f
    
    ![image.png](attachment:e2830476-8a65-4259-9b82-2bd4318db711:image.png)
    

## 복수 피쳐 기반 학습

- **2D 피쳐 기반 학습**
    
    ![image.png](attachment:8ea2070c-0849-441d-9996-56ed23cbac10:image.png)
    
    - Income : 예측하려는 라벨(반응/목표) 변수 → y로 표기
    - 각 피쳐 → x1, x2, … 로 표기
    - 측정오차 e : 피쳐 x와 독립

- **왜 f를 학습하는가?**
    1. 예측
        
        : 잘 학습된 f가 있으면 새로운 입력 X=x 에서 반응/목표 Y 를 예측할 수 있음
        
    2. 중요 특성 파악
        
        : 피쳐들의 어떤 특성이 Y를 설명하는데 중요하고 덜 중요한지 알수있음
        
    3. 해석 가능성
        
        : f의 복잡도에 따라 각 구성요소 X가 Y에 어떤 영향을 미치는지 이해 가능
        
    

## **지도학습**

- **회귀 (Regression)** : 예측값이 숫자 ( 가격, 점수, 온도, .. )
    
    > Feature로부터 label을 얼마나 정확히 예측할까?
    > 
    - 회귀 오류 : 평균재곱오류 (MSE : Mean Squared Error)
        
         : 각 데이터에서 정답과 예측의 평균 제곱 차이값
        
        ![image.png](attachment:02216365-d71a-42fc-938a-38454da169c8:image.png)
        
        → 큰 오류를 더 크게 벌함(penalty)으로, 전체 오류 수준을 한눈에 본다
        
    
    - 회귀 설명력 : R^2 (결정계수)
        
        결정계수 : 라벨의 분산 중에서 특성으로 설명되는 비율
        
        “평균만 쓰는 단순한 예측이 아닌, 얼마나 더 잘 맞추는 지를 0-1사이로 나타냄”
        
        → 1에 가까울 수록 설명력이 높음
        
         * R^2는 음수가 될 수 있dma ← 예측값들이 평균값보다도 못한다면…
        
    
- **분류** : 예측값이 범주 ( 정상/스팸, 질병의 유/무, ..)
    
    > 입력로부터 범주를 얼마나 정확히 가려낼까?
    > 
    - 범주 라벨 → 이진 / 다중
    - 정확도 : 전체 중 맞춘 비율
        
        ![image.png](attachment:9fb02d14-f360-43d7-8c65-0d85a2ecab65:image.png)
        
        but, 정확도만 보면 **불균형 데이터**(양성1%, 음성99%)에서는 전부 음성이라도 정확도가 99%로 보일수있음
        
        ⇒ 정확도만 보지 말고 다른 지표도 함께 봐야함
        

- **혼동행렬 (Confusion Matrix)**
    
    : 예측과 실제 값 사이의 관계를 행렬 형태로 표현
    
    > TP : 실제 양성, 예측도 양성
    TN : 실제 음성, 예측도 음성 
    FP : 실제는 음성인데 양성이라 함 (오탐)
    FN : 실제는 양성인데 음성이라 함 (누락)
    > 
    - 정밀도 ( Percision )
        
        : 양성이라 판정한 것 중, 진짜야 양성의 비율 = TP/(TP+FP)
        
    - 재현율 ( Sensitivity / Recall )
        
        : 진짜 양성 가운데, 잡아낸 예측 양성 비율 = TP/(TP+FN)
        

## 학습의 목적

> 학습의 목적은 테스트 예측 (일반화)
> 

: 학습 모델의 성능 평가는 모델이 처음 보는 데이터로 평가

→ 훈련 데이터에서 성능이 좋아도, 새로운 데이터에서 성능이 떨어지면 실전엔 사용못함

- **오버 피팅 (overfitting)**
    
    : 훈련 데이터의 우연한 패턴/잡음까지 외워버려서, 훈련에서는 잘 맞지만 테스트에서는 성능이 나빠지는 현상
    
    ![image.png](attachment:1f0ad438-bc1a-4d13-8a80-eb1b1a4508f5:image.png)
    
    - 왜 문제인가?
        - 표본 의존/불안정 : 훈련데이터는 모집단의 일부 표본이라 우연한 잡음이 섞임. 근데 이것에만 과하게 맞추어 학습하면 샘플 몇개만 바뀌어도 예측이 크게 흔들림 (분산됨)
        - 일반화 실패 : 보지 못한 데이터(테스트) 오류가 커짐, 모집단(population) 성능과 격차가 벌어짐
    - 오버피팅에 대한 오해
        
        분포 변화로 인한 오류 : 훈련 데이터 분포와 테스트 분포가 다름으로 성능이 떨어지는 현상
        
        분포 변화로 인한 에러 증가는 모델이 과적합하지 않아도 발생 가능
        
        ![image.png](attachment:71d2b754-6303-4fa2-abdd-73897bd24a9f:image.png)
        
        ![image.png](attachment:54cb50b0-2205-48e1-b3d0-fe91bb22626b:image.png)
        
    
    - 오버피팅 vs 언더피팅 (균형잡기)
        
        오버피팅 : 모델이 너무 복잡 → 잡음까지 학습 (테스트 성능 나쁨)
        
        언더피팅 : 모델이 단순하거나 학습이 완료되지 않음 → 중요한 패턴을 놓침 (오류 큼)
        
        ⇒ 해결 : 더 많은 데이터, 테스트 데이터를 활용한 모델 선정, 교차 검증
        
        ![image.png](attachment:e823d5e6-7eca-4848-afc6-7c60ceb682b0:image.png)
        

## 교차검증

- **테스트 성능 평가**
    
    > 훈련 오류 vs 테스트 오류
    > 
    
    훈련 오류 : 모델을 학습시킨 같은 데이터에 다시 적용해 계산한 오류
    
    테스트 오류 : 학습에 쓰지 않은 새 관측처에 대해 모델을 적용했을 때의 평균 예측 오류
    
    → (이상적 케이스) 충분히 큰 별도 테스트 데이터셋, but 현실에서 구하기 어려움
    
    ⇒ (대안) 재표본화를 통한 테스트 오류 추정
    
    : 데이터를 나눠 여러번 ‘훈련→평가’를 반복해 테스트 오류를 가늠
    
    방법 : 검증셋, K겹 교차검증
    
    장점 : 별도의 테스트데이터 없이 데이터를 더 효율적으로 사용하여 일반화 오차 추정
    

- **검증셋(Hold-out)**
    
    : 가용 샘플들을 **훈련셋** 과 **검증셋** 으로 분할
    
    → 훈련셋으로는 모델적합(학습), 검증셋으로 예측 후 검증 오류를 계산(성능평가)
    
    검증 오류는 보통 정량반응은 MSE, 범주 반응은 오분류율을 측정
    
    ![image.png](attachment:2d51f190-0537-47a4-8d62-2bf29e2b6ccd:image.png)
    
    검증셋 접근의 한계
    
    → 어떤 표본이 훈련/검증에 들어가냐에 따라 검증기반 테스트오류 추정치가 가변적
    
    검증 접근에서는 훈련셋(전체의 일부)만으로 모델을 적합하므로, 전체 데이터로 학습했을때보다 성능이 낮게 추정(=테스트 오류를 과대 추정)될 수 있음
    
    ↓ 그 해결책으로
    
- **K-겹 교차검증**
    
    : 테스트 오류 추정의 표준적 접근
    
    단계 :
    
    1. 데이터를 셔플링한 뒤, 총 n개의 데이터를 겹치지 않는 k개 그룹으로 분할
    2. 각 그룹이 번갈아 검증셋, 나머지는 훈련셋
    3. K개의 MSE를 평균해 테스트 오류를 추정
    
    ![image.png](attachment:115f8e3f-abea-4978-afe8-86832ba94125:image.png)
    
                                  ↓ 
    
- **Leave-One-Out 교차검증**
    
    훈련셋 : 관측치 하나만 제외한 나머지 전부
    
    검증셋 : 제와한 1개의 관측치
    
    : 이 과정을 n번 반복해 나온 n개의 MSE 평균으로 테스트 오류 추정
    

## 비지도 학습

- **비지도학습**
    - 정의 : 레이블 없이 데이터의 구조/패턴/집단 을 찾아내는 학습
    - 대표 과제 : 군집화, 차원축소, 밀도추정/이상치 탐지
    - 출력 : 정답예측이 아닌, **구조/요약/표현**
    
    > 무엇을 비슷함/다름으로 볼것인가
    전처리를 어떻게 할것인가
    > 
    
    비지도 vs 지도 학습
    
    ![image.png](attachment:c62cf20d-211d-48be-a5e4-dea0c8eee74d:image.png)
    
- **클러스터링**
    
    : 데이터 안에서 하위 집단을 찾는 기법들의 총칭
    
    목표 → 집단 내부의 유사, 집단 간이 상이하도록 데이터 분할
    
    유사/상이 정도는 도메인 맥락에 따라 정의가 달라질 수 있음
    
    ![image.png](attachment:fb97445e-d207-48a4-926e-ca50573b42d1:image.png)
    
    - K-평균 : K(클러스터 수) 를 미리 정해 분할
    - 계층적 군집 : K를 사전에 고정하지 않음
    
- **K-means 클러스터링**
    
    패널 : K=2, 3, 4에서 각 K-means 결과 분석 ( 2,3,4개로 분류)
    
    - 핵심 아이디어 :
        - 좋은 군집화 = 클러스터 냊부 변동이 작은 분할
        - 목표 : 클러스터 내부 변동의 합이 최소가 되도록 분할을 찾는다
        - 모든클러스터의 내부 흩어짐 총합이 가장 작은 분할
    - 알고리즘
        1. 초기화 : 관측치들에 무작위로 1 … K 클러스터를 임시 부여
        2. 반복 ( 할당이 더이상 바뀌지 않을때까지 )
            1. 각 클러스터의 중심 계산(특성 평균 벡터)
            2. 각 관측치를 가장 가까운 중심의 클러스터에 재할당
        
        ![image.png](attachment:b3b118e9-3ea4-4564-b309-4d3895371ad2:e27c171d-d0aa-48dc-b5a3-725591291687.png)
        
    
    - 특성
        
        위 반복은 매 단계별로 목표함수 값을 감소시킴 (군집 내 평균 제곱거리의 성질 때문)
        
        단, 전역 최솟값 보장은 아님 → 초기값에 따라 지역 최솟값으로 수령 가능
        
    - 다른 초기값의 영향
        
        서로 다른 초기 레이블에서 최종 분할과 목표값이 달라짐
        
        ![image.png](attachment:9eb570e8-5014-4f64-b5d1-50f5761c8f2b:image.png)
        
        → 초기화는 여러 번 시도 권장
        
    
- **계층적 군집**
    - K-means vs 계층적군집
        - K-means 는 클러스터수 K를 미리 지정해야함
        - 계층적군집은 K를 고정하지 않고 전체 구조를 덴드로그램으로 제공
        
        ![image.png](attachment:ad613af2-b3de-49ef-bdd0-3f940995f10b:image.png)
        
        - 덴드로그램에서 수평선높이(거리)를 기준으로 가위질하여 K개 군집을 얻음
    
    - 계층적 군집의 링크 유형
        - Single(최소거리) 링크 : 두 개 클러스터 내 데이터 쌍별 거리 중 **최소값**을 군집 간 거리로
        - Complete(최대거리) 링크 : 두 개 클러스터 내 데이터 쌍별 거리 중 **최대값**을 군집 간 거리로
        - Average(평균거리) 링크 : 두 개 클러스터 내 데이터 쌍별 거리 중 **평균**을 군집 간 거리로
        
        ![image.png](attachment:692bc72e-a679-473a-aa37-a1b3c2611eb1:image.png)
        
- 클러스터링 시 주의점
    
    ![image.png](attachment:5735eef3-f596-4330-8798-5dd80e061a3c:image.png)