{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# --- 라이브러리 임포트 ---\n",
        "import numpy as np\n",
        "import random\n",
        "import torch\n",
        "\n",
        "# --- 시드 고정 ---\n",
        "# PyTorch의 CPU 연산 시드 고정\n",
        "torch.manual_seed(42)\n",
        "# PyTorch의 GPU 연산 시드 고정\n",
        "torch.cuda.manual_seed(42)\n",
        "# NumPy의 난수 시드 고정\n",
        "np.random.seed(42)\n",
        "# Python 내장 random 모듈의 시드 고정\n",
        "random.seed(42)\n",
        "\n",
        "# CuDNN 관련 설정 (GPU 연산의 재현성을 위함)\n",
        "# 결정론적 알고리즘을 사용하도록 설정하여 실행 시마다 동일한 결과를 보장\n",
        "torch.backends.cudnn.deterministic = True\n",
        "# 내장된 벤치마크 기능을 비활성화하여 재현성 유지\n",
        "torch.backends.cudnn.benchmark = False"
      ],
      "metadata": {
        "id": "3CKcx_gALf6Z"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Linear Probing"
      ],
      "metadata": {
        "id": "GCH_5-5XLhU6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 준비과정"
      ],
      "metadata": {
        "id": "TNy4SZrWMAsB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 필수 라이브러리 임포트 ---\n",
        "import torch\n",
        "import torch.nn as nn                       # 신경망 모델을 구성하기 위한 모듈 (레이어, 손실 함수 등)\n",
        "import torch.optim as optim                 # 모델을 최적화하기 위한 알고리즘 (SGD, Adam 등)\n",
        "import torchvision                          # 컴퓨터 비전 관련 유명 데이터셋, 모델, 변환 기능을 제공\n",
        "import torchvision.transforms as transforms # 이미지 데이터를 전처리(변환)하기 위한 기능\n",
        "from tqdm import tqdm\n",
        "\n",
        "# --- 장치 설정 ---\n",
        "# torch.cuda.is_available() 함수는 GPU 사용이 가능한지 확인\n",
        "# 가능하면 'cuda' (GPU)를, 불가능하면 'cpu'를 device 변수에 할당\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"사용 중인 장치:\", device)\n",
        "\n",
        "\n",
        "\n",
        "# CIFAR-10 데이터셋 로드 (train 50,000장, test 10,000장)\n",
        "# --- CIFAR-10 데이터셋 로드 ---\n",
        "# root: 데이터가 저장될 경로\n",
        "# train=True: 훈련용 데이터셋을 불러옴\n",
        "# download=True: 해당 경로에 데이터가 없으면 다운로드\n",
        "# transform: 데이터 변환기 적용 -> 데이터를 먼저 확인하기 위해 False 으로 설정\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=False)\n",
        "testset  = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=False)\n",
        "\n",
        "print(trainset.data.shape, testset.data.shape)\n",
        "\n",
        "\n",
        "# CIFAR_10 데이터셋의 평균과 표준편차 계산\n",
        "data_tensor = torch.from_numpy(trainset.data)\n",
        "\n",
        "# 평균 계산 (배치, 높이, 너비 차원에 대해)\n",
        "mean = torch.mean(data_tensor.float() / 255.0, dim=(0, 1, 2))\n",
        "\n",
        "# 표준편차 계산 (배치, 높이, 너비 차원에 대해)\n",
        "std = torch.std(data_tensor.float() / 255.0, dim=(0, 1, 2))\n",
        "\n",
        "print(\"CIFAR-10 학습 데이터의 픽셀별 평균:\", mean)\n",
        "print(\"CIFAR-10 학습 데이터의 픽셀별 표준편차:\", std)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P4HGE2zTMLkZ",
        "outputId": "92552a02-b491-4ba2-da9f-3eaa11953ecc"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "사용 중인 장치: cuda\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170M/170M [00:03<00:00, 49.1MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(50000, 32, 32, 3) (10000, 32, 32, 3)\n",
            "CIFAR-10 학습 데이터의 픽셀별 평균: tensor([0.4914, 0.4822, 0.4465])\n",
            "CIFAR-10 학습 데이터의 픽셀별 표준편차: tensor([0.2470, 0.2435, 0.2616])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 정규화"
      ],
      "metadata": {
        "id": "SmuYIKLFMQkI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 데이터 변환기(Transformer) 정의 ---\n",
        "# 이미지에 적용할 전처리 단계를 Compose를 사용해 묶어줍니다.\n",
        "\n",
        "# 학습 데이터: 224로 리사이즈 후 텐서화 및 정규화\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),      # ResNet18 입력 크기인 224x224로 크기 변경\n",
        "    transforms.ToTensor(),              # PyTorch 텐서로 변환\n",
        "\n",
        "    # 픽셀 값을 특정 평균(mean)과 표준편차(std)로 정규화\n",
        "    transforms.Normalize(mean,  # CIFAR-10 평균\n",
        "                         std)   # CIFAR-10 표준편차\n",
        "])\n",
        "\n",
        "# 문제 1: 데이터 전처리 과정을 위한 변환기(Transformer)를 정의하세요.\n",
        "# 테스트 데이터: 리사이즈 후 텐서화 및 정규화 (학습과 동일하게)\n",
        "test_transform = transforms.Compose([\n",
        "    # [START CODE]\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean, std)\n",
        "    # [END CODE]\n",
        "])\n",
        "\n",
        "# 위에서 정의한 변환기를 사용하여 CIFAR-10 데이터셋 로드 (train 50,000장, test 10,000장)\n",
        "# root: 데이터가 저장될 경로\n",
        "# train=True: 훈련용 데이터셋을 불러옴\n",
        "# download=True: 해당 경로에 데이터가 없으면 다운로드\n",
        "# transform: 위에서 정의한 데이터 변환기 적용\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=train_transform)\n",
        "testset  = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=test_transform)\n",
        "\n",
        "# --- DataLoader 생성 ---\n",
        "# DataLoader는 데이터를 미니배치(mini-batch) 단위로 묶어주는 역할을 함\n",
        "# batch_size: 한 번에 모델에 입력할 데이터(이미지)의 개수\n",
        "# shuffle=True: 훈련 시 데이터를 무작위로 섞어 모델이 데이터 순서에 과적합되는 것을 방지\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=256, shuffle=True)\n",
        "testloader  = torch.utils.data.DataLoader(testset, batch_size=256, shuffle=False)\n",
        "\n",
        "print(\"훈련 배치 개수:\", len(trainloader), \"테스트 배치 개수:\", len(testloader))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fTY6BZ3eMTfk",
        "outputId": "31198f57-ffe2-482f-fb5f-f91523baef38"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "훈련 배치 개수: 196 테스트 배치 개수: 40\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ResNet 가져오기"
      ],
      "metadata": {
        "id": "V849_sSCNhyY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 선형 계층만 학습되도록 설정"
      ],
      "metadata": {
        "id": "QW5ugsNaOisJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = torchvision.models.resnet18(pretrained=True)\n",
        "\n",
        "# --- 선형 프로빙(Linear Probing)을 위한 모델 수정 ---\n",
        "\n",
        "# 문제 2: 선형 프로빙을 위해 ResNet-18 모델의 마지막 층을 수정하세요.\n",
        "# 1. 마지막 분류층(Fully Connected Layer) 교체\n",
        "# 기존 ResNet-18의 마지막 층(model.fc)은 ImageNet의 1000개 클래스를 분류\n",
        "# 이를 CIFAR-10의 10개 클래스를 분류하도록 새로운 선형 레이어로 교체\n",
        "# model.fc.in_features는 기존 fc 레이어의 입력 뉴런 수를 그대로 사용\n",
        "# [START CODE]\n",
        "model.fc = nn.Linear(model.fc.in_features, 10)\n",
        "# [END CODE]\n",
        "\n",
        "# 문제 3: 선형 프로빙을 위해 ResNet-18 모델의 마지막 층을 업데이트가 되지 않도록 가중치를 동결하세요.\n",
        "# 2. 마지막 층을 제외한 모든 파라미터(가중치)를 동결(freeze)\n",
        "# == 최종 fc 레이어를 제외한 모든 파라미터를 동결\n",
        "# `param.requires_grad = False`로 설정하면 해당 파라미터는 학습 중에 업데이트되지 않음\n",
        "# [START CODE]\n",
        "for name, param in model.named_parameters():\n",
        "    if 'fc' not in name:\n",
        "        param.requires_grad = False\n",
        "\n",
        "# [END CODE]\n",
        "\n",
        "# 장치를 GPU로 이동\n",
        "model = model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fRrXobGZOlHZ",
        "outputId": "ab6fe34b-f72d-41e0-ea98-fa6d4d546f77"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 학습 시작"
      ],
      "metadata": {
        "id": "sc2M4aYbPbfm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 문제 4: 손실 함수를 정의하세요\n",
        "# 손실 함수로 CrossEntropyLoss를 정의\n",
        "# [START CODE]\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "# [END CODE]\n",
        "\n",
        "# 문제 5: 옵티마이저를 정의하세요\n",
        "# 옵티마이저로 SGD(Stochastic Gradient Descent)를 정의, 학습률은 0.001 으로 설정\n",
        "# 동결된 파라미터 제외, 마지막 레이어만 최적화\n",
        "# 즉, 마지막 레이어의 파라미터만 옵티마이저에 전달하여 마지막 레이어만 최적화되도록 설정\n",
        "# [START CODE]\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.001)\n",
        "# [END CODE]\n",
        "\n",
        "# 에포크(epoch) 수 설정. 에포크는 전체 훈련 데이터를 한 번 모두 사용하는 것을 의미\n",
        "num_epochs = 5\n",
        "\n",
        "# 문제 6: 모델 학습을 위한 반복문을 작성하세요\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()       # 모델을 학습 모드로 설정\n",
        "    running_loss = 0.0  # 에포크 동안의 총 손실을 기록할 변수\n",
        "\n",
        "    # trainloader에서 미니배치 단위로 데이터를 가져와 반복\n",
        "    for inputs, labels in tqdm(trainloader):\n",
        "\n",
        "        # 입력 데이터와 정답 레이블을 지정된 장치(GPU)로 이동\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        # --- 핵심 학습 단계 ---\n",
        "        # [START CODE]\n",
        "\n",
        "        # 1. 옵티마이저의 그래디언트(gradient)를 0으로 초기화\n",
        "        # 이전 배치의 그래디언트가 다음 배치에 영향을 주지 않도록 함\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # 2. 모델에 입력을 넣어 순전파(forward pass) 진행 및 출력(outputs) 계산\n",
        "        outputs = model(inputs)\n",
        "\n",
        "        # 3. 모델의 출력과 실제 정답을 비교하여 손실(loss) 계산\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # 4. 역전파(backward pass)를 통해 각 파라미터에 대한 그래디언트 계산\n",
        "        loss.backward()\n",
        "\n",
        "        # 5. 옵티마이저를 사용해 모델의 파라미터(가중치)를 업데이트\n",
        "        # requires_grad=True로 설정된 파라미터만 업데이트됨 (여기서는 fc 층만)\n",
        "        optimizer.step()\n",
        "\n",
        "        # [END CODE]\n",
        "\n",
        "        # 현재 배치의 손실을 running_loss에 더함\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    # 전체 에포크가 끝난 후 평균 훈련 손실을 계산하고 출력\n",
        "    avg_loss = running_loss / len(trainloader)\n",
        "    print(f\"[Epoch {epoch+1}/{num_epochs}] 평균 훈련 손실: {avg_loss:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5OnEMqsmPVRm",
        "outputId": "7dedd09c-ef18-4e21-a63c-5a09b9527f32"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 196/196 [02:26<00:00,  1.34it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 1/5] 평균 훈련 손실: 2.1578\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 196/196 [02:31<00:00,  1.29it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 2/5] 평균 훈련 손실: 1.8242\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 196/196 [02:26<00:00,  1.34it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 3/5] 평균 훈련 손실: 1.5936\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 196/196 [02:27<00:00,  1.33it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 4/5] 평균 훈련 손실: 1.4279\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 196/196 [02:21<00:00,  1.38it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 5/5] 평균 훈련 손실: 1.3072\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 학습 결과 확인"
      ],
      "metadata": {
        "id": "05m7_o8SQuH1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델을 평가 모드로 설정\n",
        "# 이 모드에서는 드롭아웃(Dropout)이나 배치 정규화(Batch Normalization) 등이 비활성화되어 일관된 예측 결과를 얻을 수 있음\n",
        "model.eval()\n",
        "\n",
        "correct = 0   # 맞춘 예측 개수\n",
        "total = 0     # 전체 데이터 개수\n",
        "\n",
        "# 그래디언트 계산을 비활성화하는 컨텍스트\n",
        "with torch.no_grad():\n",
        "\n",
        "    # testloader에서 미니배치 단위로 데이터를 가져와 반복\n",
        "    for inputs, labels in tqdm(testloader):\n",
        "\n",
        "        # 입력 데이터와 정답 레이블을 장치(GPU)로 이동\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        # 모델에 입력을 넣어 출력 계산\n",
        "        outputs = model(inputs)\n",
        "\n",
        "        # 문제 7: 예측 및 정확도를 계산하세요\n",
        "        # [START CODE]\n",
        "        # --- 예측 및 정확도 계산 ---\n",
        "        # outputs.data는 모델의 최종 출력(logits)\n",
        "        # torch.max(..., 1)은 각 샘플에 대해 가장 높은 값과 그 인덱스를 반환\n",
        "        # `_`는 값(무시), `predicted`는 인덱스(예측된 클래스)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        # [END CODE]\n",
        "\n",
        "        total += labels.size(0) # 현재 배치의 데이터 개수를 total에 더함\n",
        "\n",
        "        # 예측이 정답과 일치하는 개수를 세어 correct에 더함\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "# 전체 정확도 계산 및 출력\n",
        "accuracy = 100 * correct / total\n",
        "print(f\"테스트 데이터 정확도: {accuracy:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TqmGYexkQxVt",
        "outputId": "84f9cec5-a03b-477f-ef1a-dff77f02b2e7"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 40/40 [00:27<00:00,  1.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "테스트 데이터 정확도: 66.80%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 데이터 증강(Data Augmentation) & Fine Tuning"
      ],
      "metadata": {
        "id": "qDSD3kO8ShBz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 문제 8: 데이터 증강을 적용한 변환기를 정의하세요\n",
        "# --- 데이터 증강이 포함된 변환기 정의 ---\n",
        "train_transform_aug = transforms.Compose([\n",
        "    # [START CODE]\n",
        "    # 32x32 이미지 주변에 4픽셀의 패딩(padding)을 추가한 뒤, 무작위로 32x32 영역을 잘라냄\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    # 50% 확률로 이미지를 좌우로 뒤집음\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\n",
        "    # [END CODE]\n",
        "    transforms.Resize((224, 224)), # 이미지 크기 조절\n",
        "    transforms.ToTensor(), # 텐서로 변환\n",
        "    transforms.Normalize(mean=mean, std=std) # 정규화\n",
        "])\n",
        "\n",
        "# 데이터 증강이 적용된 새로운 훈련 데이터셋 및 DataLoader 생성\n",
        "trainset_aug = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=train_transform_aug)\n",
        "trainloader_aug = torch.utils.data.DataLoader(trainset_aug, batch_size=256, shuffle=True)"
      ],
      "metadata": {
        "id": "I3j6HDsUSn9d"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 문제 9: 미세 조정을 위해 모델 파라미터 동결을 해제하세요\n",
        "# [START CODE]\n",
        "# --- 모델의 모든 파라미터 동결 해제 ---\n",
        "# requires_grad를 True로 설정하여 모든 파라미터가 학습 중에 업데이트되도록 함\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = True\n",
        "\n",
        "# [END CODE]\n",
        "\n",
        "# --- 새로운 옵티마이저와 스케줄러 정의 ---\n",
        "# 이제 model.parameters()를 전달하여 모델의 모든 파라미터를 최적화 대상으로 함\n",
        "# 학습률(lr)은 기존보다 약간 낮게 설정하여 섬세하게 조정\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.0005, momentum=0.9)\n",
        "\n",
        "# StepLR 스케줄러: 특정 단계(step_size)마다 학습률에 감마(gamma)를 곱해 감소시킴\n",
        "# step_size=5: 5 에포크마다\n",
        "# gamma=0.1: 학습률을 0.1배로 줄임\n",
        "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)"
      ],
      "metadata": {
        "id": "vdlIR1uhSxZc"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 학습 시작"
      ],
      "metadata": {
        "id": "GhUA7SiJVYua"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 5\n",
        "for epoch in range(num_epochs):\n",
        "    model.train() # 훈련 모드\n",
        "    running_loss = 0.0\n",
        "\n",
        "    # 증강이 적용된 데이터로 훈련\n",
        "    for inputs, labels in tqdm(trainloader_aug):\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    # 에포크 결과 출력\n",
        "    avg_loss = running_loss / len(trainloader_aug)\n",
        "    print(f\"[Fine-tune Epoch {epoch+1}/{num_epochs}] 평균 훈련 손실: {avg_loss:.4f}, 현재 학습률: {optimizer.param_groups[0]['lr']:.6f}\")\n",
        "\n",
        "    # 문제 10: 학습률 스케줄러를 통해 학습률을 조정하세요\n",
        "    # [START CODE]\n",
        "    # --- 학습률 스케줄러 업데이트 ---\n",
        "    # 정의된 규칙에 따라 학습률을 조정\n",
        "    scheduler.step()\n",
        "\n",
        "    # [END CODE]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zZuFgEgaUvx7",
        "outputId": "d26d93ab-a3ab-4d14-d028-da379064e9bf"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 196/196 [03:54<00:00,  1.20s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fine-tune Epoch 1/5] 평균 훈련 손실: 0.7636, 현재 학습률: 0.000500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 196/196 [03:54<00:00,  1.19s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fine-tune Epoch 2/5] 평균 훈련 손실: 0.4149, 현재 학습률: 0.000500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 196/196 [03:55<00:00,  1.20s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fine-tune Epoch 3/5] 평균 훈련 손실: 0.3223, 현재 학습률: 0.000500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 196/196 [03:55<00:00,  1.20s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fine-tune Epoch 4/5] 평균 훈련 손실: 0.2755, 현재 학습률: 0.000500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 196/196 [03:54<00:00,  1.20s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fine-tune Epoch 5/5] 평균 훈련 손실: 0.2455, 현재 학습률: 0.000500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 미세 조정 후 모델 평가 ---\n",
        "model.eval() # 평가 모드\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in tqdm(testloader):\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        outputs = model(inputs)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "fine_tune_acc = 100 * correct / total\n",
        "print(f\"미세 조정 후 테스트 정확도: {fine_tune_acc:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lj7ajFe9U8dS",
        "outputId": "961964b7-7193-4048-c05c-6e403ae542f4"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 40/40 [00:28<00:00,  1.42it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "미세 조정 후 테스트 정확도: 92.27%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), 'model.pth')"
      ],
      "metadata": {
        "id": "ZEwLKZMxVT9c"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TsXFRfDqaibV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}